{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58bf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import monai\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 设置参数\n",
    "images_file = '../GOALS2022-Train/Train/Image'  # 训练图像路径\n",
    "# gt_file = '../GOALS2022-Train/Train/Layer_Masks'\n",
    "image_size = 648 # 输入图像统一尺寸\n",
    "image_size2 = 648\n",
    "#val_ratio = 0.1  # 训练/验证图像划分比例\n",
    "batch_size = 4 # 批大小\n",
    "iters = 10000 # 训练迭代次数\n",
    "#optimizer_type = 'adam' # 优化器, 可自行使用其他优化器，如SGD, RMSprop,...\n",
    "num_workers = 8 # 数据加载处理器个数\n",
    "#init_lr = 1e-3 # 初始学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4076dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dir = './logs_resnet50_v2'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print('cuda',torch.cuda.is_available())\n",
    "print('gpu number',torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))\n",
    "summaryWriter = SummaryWriter(summary_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "filelists = os.listdir(images_file)\n",
    "print(filelists)\n",
    "train_filelists, val_filelists = train_test_split(filelists, test_size = val_ratio, random_state=42)\n",
    "print(\"Total Nums: {}, train: {}, val: {}\".format(len(filelists), len(train_filelists), len(val_filelists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载\n",
    "class GOALS_sub2_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                dataset_root,\n",
    "                label_file='',\n",
    "                filelists=None,\n",
    "                mode='train'):\n",
    "        self.dataset_root = dataset_root\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'train' or self.mode == \"val\" :  \n",
    "            label = {row['ImgName']:row[1]\n",
    "                    for _, row in pd.read_excel(label_file,engine='openpyxl').iterrows()}\n",
    "            self.file_list = [[f, label[int(f.split('.')[0])]] for f in os.listdir(dataset_root)]\n",
    "\n",
    "        elif self.mode == \"test\":\n",
    "            self.file_list = [[f, None] for f in os.listdir(dataset_root)]\n",
    "        \n",
    "        if filelists is not None:\n",
    "            self.file_list = [item for item in self.file_list if item[0] in filelists]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        real_index, label = self.file_list[idx]\n",
    "        #label = [label]\n",
    "        img_path = os.path.join(self.dataset_root, real_index)    \n",
    "        img = Image.open(img_path)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        # img = img.resize((image_size2,image_size))\n",
    "        # normlize on GPU to save CPU Memory and IO consuming.\n",
    "        # img = (img / 255.).astype(\"float32\")\n",
    "        if self.mode == \"train\":\n",
    "            im_aug = transforms.Compose([\n",
    "                #tfs.Resize(120),\n",
    "                transforms.RandomCrop(image_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(20),\n",
    "                #transforms.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5),\n",
    "                #transforms.RandomPerspective(),\n",
    "                #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1.5)),\n",
    "                #transforms.RandomInvert(),\n",
    "                #transforms.RandomPosterize(bits=2),\n",
    "                #transforms.RandomAdjustSharpness(sharpness_factor=2)\n",
    "                #transforms.RandomAutocontrast(),\n",
    "                #transforms.RandomEqualize()\n",
    "            ])\n",
    "            img = im_aug(img)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.mode == 'test' or self.mode == \"val\":    \n",
    "            im_aug = transforms.Compose([\n",
    "                transforms.CenterCrop(image_size)\n",
    "            ])\n",
    "            img = im_aug(img)\n",
    "        \n",
    "        img = transforms.PILToTensor()(img)\n",
    "        #print(img.shape)\n",
    "\n",
    "        #img = img.transpose(2, 0, 1) # H, W, C -> C, H, W\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return img, real_index\n",
    "\n",
    "        if self.mode == \"train\" or self.mode == \"val\" :           \n",
    "            return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e39905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化并检查数据加载\n",
    "_train = GOALS_sub2_dataset(dataset_root=images_file, \n",
    "                            label_file = '../GOALS2022-Train/Train/Train_GC_GT.xlsx',\n",
    "                            filelists = train_filelists,\n",
    "                            mode = 'train')\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    img, lab = _train.__getitem__(i)\n",
    "    img = img.numpy()\n",
    "    print(img.shape)\n",
    "    print(lab)\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(img.transpose(1, 2, 0),cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "_val = GOALS_sub2_dataset(dataset_root=images_file, \n",
    "                          label_file = '../GOALS2022-Train/Train/Train_GC_GT.xlsx',\n",
    "                          filelists = val_filelists,\n",
    "                          mode = 'val')\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(5):\n",
    "    img, lab = _val.__getitem__(i)\n",
    "    img = img.numpy()\n",
    "    print(img.shape)\n",
    "    print(lab)\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(img.transpose(1, 2, 0),cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab534db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet50', pretrained=True, num_classes=2, in_chans=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fc6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(1,1,684,684)\n",
    "output = model(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db04079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce3059",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GOALS_sub2_dataset(dataset_root=images_file, \n",
    "                            label_file = '../GOALS2022-Train/Train/Train_GC_GT.xlsx',\n",
    "                            filelists = train_filelists,\n",
    "                            mode = 'train')\n",
    "\n",
    "val_dataset = GOALS_sub2_dataset(dataset_root=images_file, \n",
    "                          label_file = '../GOALS2022-Train/Train/Train_GC_GT.xlsx',\n",
    "                          filelists = val_filelists,\n",
    "                          mode = 'val')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=False, num_workers=8,\n",
    "                        pin_memory=True)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #print('lr now = ', get_learning_rate(optimizer))\n",
    "    avg_loss_list = []\n",
    "    \n",
    "    num_correct = 0\n",
    "    model.train()\n",
    "    with torch.enable_grad():\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            \n",
    "            img = (data[0])\n",
    "            labels = (data[1])\n",
    "            \n",
    "            img = img.cuda().float()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            \n",
    "            #print(img.shape)\n",
    "            #print(labels)\n",
    "            \n",
    "\n",
    "            logits = model(img)\n",
    "            #print(logits)\n",
    "            loss = criterion(logits, labels)\n",
    "            #print(loss)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            #print(pred)\n",
    "            #print(labels)\n",
    "            num_correct += torch.eq(pred, labels).sum().float().item()\n",
    "            #print(num_correct)\n",
    "            #print(abc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "                \n",
    "            avg_loss_list.append(loss.item())\n",
    "\n",
    "        avg_loss = np.array(avg_loss_list).mean()\n",
    "        print(\"[TRAIN] epoch={}/{} avg_loss={:.4f} avg_acc={:.4f}\".format(epoch, num_epochs, avg_loss, num_correct/len(train_loader.dataset)))\n",
    "        summaryWriter.add_scalars('loss', {\"loss\": (avg_loss)}, epoch)\n",
    "        summaryWriter.add_scalars('acc', {\"acc\": num_correct/len(train_loader.dataset)}, epoch)\n",
    "    \n",
    "    model.eval()\n",
    "    num_correct_val = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader):\n",
    "            \n",
    "            img = (data[0])\n",
    "            labels = (data[1])            \n",
    "            img = img.cuda().float()\n",
    "            labels = labels.cuda()\n",
    "            logits = model(img)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            num_correct_val += torch.eq(pred, labels).sum().float().item()\n",
    "        val_acc = num_correct_val/len(val_loader.dataset)\n",
    "        print(\"[EVAL] epoch={}/{}  val_acc={:.4f}\".format(epoch, num_epochs, val_acc))\n",
    "        summaryWriter.add_scalars('val_acc', {\"val_acc\": val_acc}, epoch)\n",
    "        \n",
    "    scheduler.step()\n",
    "    filepath = '/home/liyihao/OVH/home/yihao/GOALS/task2_resnet_v3/weights'\n",
    "    folder = os.path.exists(filepath)\n",
    "    if not folder:\n",
    "        # 判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(filepath)\n",
    "    if val_acc>0.99:\n",
    "        path = '/home/liyihao/OVH/home/yihao/GOALS/task2_resnet_v3/weights/model' + str(epoch) + '_'+ str(val_acc) + '.pth'\n",
    "        torch.save(model.state_dict(), path)     \n",
    "    \n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
