{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as trans\n",
    "# from dataset_functions.task1_dataset import OCTDataset\n",
    "from dataset_functions.transforms import img_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.4850]],\n",
      "\n",
      "         [[0.4560]],\n",
      "\n",
      "         [[0.4060]]]])\n",
      "torch.Size([1, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1)\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nums: 200, train: 160, val: 40\n",
      "['0062_2.png', '0025_2.png', '0065_2.png', '0009_2.png', '0045_2.png', '0071_1.png', '0057_2.png', '0037_2.png', '0064_2.png', '0088_2.png', '0066_2.png', '0035_1.png', '0072_2.png', '0049_1.png', '0030_1.png', '0012_2.png', '0097_2.png', '0052_2.png', '0090_1.png', '0067_2.png', '0018_1.png', '0074_1.png', '0068_2.png', '0019_1.png', '0085_2.png', '0063_1.png', '0035_2.png', '0027_2.png', '0080_1.png', '0059_2.png', '0019_2.png', '0036_1.png', '0032_1.png', '0093_2.png', '0033_1.png', '0028_1.png', '0055_1.png', '0066_1.png', '0013_1.png', '0060_2.png']\n"
     ]
    }
   ],
   "source": [
    "# 设置参数\n",
    "image_file = '../datasets/Train/Image_aug2' \n",
    "gt_file = '../datasets/Train/Layer_Masks_aug2'\n",
    "layer_file = '../datasets/Train/Layer_show_aug2'\n",
    "# image_size = 256 # 统一输入图像尺寸\n",
    "val_ratio = 0.2 # 验证/训练图像划分比例\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "filelists = os.listdir(image_file)\n",
    "train_filelists, val_filelists = train_test_split(filelists, test_size = val_ratio,random_state = 42)\n",
    "print(\"Total Nums: {}, train: {}, val: {}\".format(len(filelists), len(train_filelists), len(val_filelists)))\n",
    "print(val_filelists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "torch.Size([800, 800])\n",
      "tensor([[3, 3, 3,  ..., 3, 3, 3],\n",
      "        [3, 3, 3,  ..., 3, 3, 3],\n",
      "        [3, 3, 3,  ..., 3, 3, 3],\n",
      "        ...,\n",
      "        [3, 3, 3,  ..., 3, 3, 3],\n",
      "        [3, 3, 3,  ..., 3, 3, 3],\n",
      "        [3, 3, 3,  ..., 3, 3, 3]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhouziyu/miniconda3/envs/ipy/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:1766: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  \"blur_limit and sigma_limit minimum value can not be both equal to 0. \"\n"
     ]
    }
   ],
   "source": [
    "class OCTDataset(Dataset):\n",
    "    def __init__(self, image_transforms, image_dir, filelists=None, gt_dir=None, mode='train'):\n",
    "        super(OCTDataset, self).__init__()\n",
    "        self.image_transforms = image_transforms\n",
    "        self.image_dir = image_dir\n",
    "        self.filelists = filelists\n",
    "        if self.filelists == None:\n",
    "            self.filelists = os.listdir(self.image_dir)\n",
    "        self.gt_dir = gt_dir\n",
    "        self.mode = mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_index = self.filelists[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_index)\n",
    "        img = cv2.imread(img_path)\n",
    "        h, w, c = img.shape\n",
    "\n",
    "        gt_img = cv2.imread(os.path.join(self.gt_dir, img_index))\n",
    "        gt_img = gt_img[:,:,1]\n",
    "        gt_img = gt_img.astype(np.uint8)\n",
    "        # gt_img = torch.from_numpy(gt_img)\n",
    "        \n",
    "        if self.mode == 'train' or self.mode == 'val':            \n",
    "            # 像素值为0的是RNFL(类别 0)，像素值为80的是GCIPL(类别 1)，像素值为160的是脉络膜(类别 2)，像素值为255的是其他（类别3）\n",
    "            gt_img[gt_img == 80] = 1\n",
    "            gt_img[gt_img == 160] = 2\n",
    "            gt_img[gt_img == 255] = 3\n",
    "        # single_label_list = []\n",
    "        # for c in range(4):\n",
    "        #     single_label = (gt_img==c)\n",
    "        #     single_label_list.append(single_label)\n",
    "        # labels_one_hot = torch.stack(tuple(single_label_list), axis = 0)\n",
    "        # labels_one_hot = labels_one_hot.numpy()\n",
    "        # # labels_one_hot = np.transpose(labels_one_hot,[1,2,0]) \n",
    "        # labels_one_hot = labels_one_hot.astype(np.uint8)\n",
    "            \n",
    "            # gt_img = cv2.resize(gt_img, (800, 800))\n",
    "            # gt_img = torch.from_numpy(gt_img)\n",
    "            # gt_img = torch.squeeze(gt_img, 0)\n",
    "            # gt_img = gt_img[:,:,1] # 取一个通道\n",
    "        \n",
    "        if self.image_transforms is not None:\n",
    "            out = self.image_transforms(image=img,mask=gt_img)\n",
    "            img, gt_img = out['image'], out['mask']\n",
    "\n",
    "        if self.mode == 'train' or self.mode == 'val':            \n",
    "            return img.float(), gt_img.long() # img, labels_one_hot \n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return img.float(), img_index, h, w\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelists)\n",
    "\n",
    "\n",
    "img_train_transforms = img_transforms(applied_types='train')\n",
    "img_val_transforms = img_transforms(New_size = (800,800), applied_types='val')\n",
    "val_dataset = OCTDataset(image_transforms=img_val_transforms, image_dir=image_file, filelists=val_filelists, gt_dir=gt_file, mode='val')\n",
    "# val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "img, gt_img = val_dataset.__getitem__(0)\n",
    "print(torch.unique(gt_img))\n",
    "print(gt_img.shape)\n",
    "print(gt_img)# 输入：image_path为数据集路径，filelists为此次调用OCTDataset的图像列表（训练或者验证的图像列表），gt_path为分割的ground truth\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800, 5])\n",
      "tensor([[[0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "def get_layer_label(input, layer):\n",
    "    all_1 = np.ones((800,800))\n",
    "    layer_diff = layer - input\n",
    "    layer_diff[layer_diff != 0] = 1\n",
    "    layer = layer_diff * layer\n",
    "    location1 = np.all((layer == [0,0,1]), axis=2)\n",
    "    location2 = np.all((layer == [0,1,0]), axis=2)\n",
    "    location3 = np.all((layer == [1,0,0]), axis=2)\n",
    "    location4 = np.all((layer == [1,1,0]), axis=2)\n",
    "    location5 = np.all((layer == [1,0,1]), axis=2)\n",
    "    layer_label1 = all_1 * location1\n",
    "    # layer_label1 = np.repeat(layer_label1,repeats = 3,axis = 2)\n",
    "    layer_label2 = all_1 * location2\n",
    "    layer_label3 = all_1 * location3\n",
    "    layer_label4 = all_1 * location4\n",
    "    layer_label5 = all_1 * location5\n",
    "    layer_label = np.stack((layer_label1, layer_label2, layer_label3, layer_label4, layer_label5), axis=2) \n",
    "    return layer_label # 800*800*5\n",
    "\n",
    "class OCTDataset_layermask(Dataset):\n",
    "    def __init__(self, image_transforms, image_path, layer_path, filelists=None, gt_path=None, mode='train'):\n",
    "        super(OCTDataset_layermask, self).__init__()\n",
    "        self.image_transforms = image_transforms\n",
    "        self.image_path = image_path\n",
    "        self.layer_path = layer_path\n",
    "        self.filelists = filelists\n",
    "        if self.filelists == None:\n",
    "            self.filelists = os.listdir(self.image_path)\n",
    "        self.gt_path = gt_path\n",
    "        self.mode = mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_index = self.filelists[idx]\n",
    "        img_path = os.path.join(self.image_path, img_index)\n",
    "        img = cv2.imread(img_path)\n",
    "        h, w, c = img.shape\n",
    "\n",
    "        # img = cv2.resize(img, (self.image_size, self.image_size))\n",
    "\n",
    "        if self.mode == 'train' or self.mode == 'val':      \n",
    "            gt_img = cv2.imread(os.path.join(self.gt_path, img_index))\n",
    "            layer_img = cv2.imread(os.path.join(self.layer_path, img_index))\n",
    "            # if len(gt_img.shape==3):\n",
    "            gt_img = gt_img[:,:,0] # 取一个通道\n",
    "            gt_img = gt_img.astype(np.uint8)      \n",
    "            # 像素值为0的是RNFL(类别 0)，像素值为80的是GCIPL(类别 1)，像素值为160的是脉络膜(类别 2)，像素值为255的是其他（类别3）\n",
    "            gt_img[gt_img == 80] = 1\n",
    "            gt_img[gt_img == 160] = 2\n",
    "            gt_img[gt_img == 255] = 3\n",
    "\n",
    "            layer_label = get_layer_label(img/255, layer_img/255).astype(np.uint8)\n",
    "            layer_label = torch.from_numpy(layer_label)\n",
    "\n",
    "\n",
    "        if self.image_transforms is not None:\n",
    "            if self.mode == 'test':\n",
    "                out = self.image_transforms(image=img)\n",
    "                img = out['image']\n",
    "            else:\n",
    "                out = self.image_transforms(image=img,mask=gt_img)\n",
    "                img, gt_img = out['image'], out['mask']\n",
    "\n",
    "        img = img/255\n",
    "\n",
    "        if self.mode == 'train' or self.mode == 'val':             \n",
    "            return img.float(), gt_img.long(), layer_label.long()\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return img.float(), img_index, h, w\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelists)\n",
    "\n",
    "\n",
    "img_train_transforms = img_transforms(applied_types='train')\n",
    "img_val_transforms = img_transforms(New_size = (800,800), applied_types='val')\n",
    "val_dataset = OCTDataset_layermask(image_transforms=img_val_transforms, image_path=image_file,\n",
    "                                layer_path=layer_file, filelists=val_filelists, gt_path=gt_file, mode='val')\n",
    "# val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "img, gt_img, layer_label = val_dataset.__getitem__(0)\n",
    "# print(torch.unique(gt_img))\n",
    "print(layer_label.shape)\n",
    "print(layer_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('ipy': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e3406b8e7a9b61a02cd4d7c6ceeafe1f24972ddbebfd203e67c74bc840a1e0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
